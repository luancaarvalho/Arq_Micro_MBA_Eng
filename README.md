# Arquitetura de MicroserviÃ§os - MBA Engenharia de Dados

RepositÃ³rio da disciplina de Arquitetura de MicroserviÃ§os do MBA em Engenharia de Dados.

## ğŸ“š Estrutura do RepositÃ³rio

Este repositÃ³rio contÃ©m as aulas prÃ¡ticas e o trabalho final da disciplina:

```
Arq_Micro_MBA_Eng/
â”œâ”€â”€ aula_01/          # IntroduÃ§Ã£o ao Kafka
â”œâ”€â”€ aula_02/          # Schemas e SerializaÃ§Ã£o
â”œâ”€â”€ aula_03/          # TÃ³picos, PartiÃ§Ãµes, ReplicaÃ§Ã£o e Connect
â”œâ”€â”€ aula_04/          # Domain-Driven Design
â”œâ”€â”€ aula_05/          # CQRS e TransaÃ§Ãµes
â””â”€â”€ trabalho/         # Trabalho Final: Pipeline CDC Fim a Fim
```

## ğŸ¯ Trabalho Final: Pipeline CDC Fim a Fim

### DescriÃ§Ã£o

O trabalho final implementa um **pipeline completo de Change Data Capture (CDC)** que utiliza **mudanÃ§as lÃ³gicas do banco de dados** como fonte de dados. O objetivo Ã© demonstrar a captura em tempo real de eventos de INSERT, UPDATE e DELETE atravÃ©s da replicaÃ§Ã£o lÃ³gica do PostgreSQL e sua distribuiÃ§Ã£o para mÃºltiplos destinos.

### Conceito Principal

O pipeline utiliza a **replicaÃ§Ã£o lÃ³gica do PostgreSQL** (WAL - Write-Ahead Log) como fonte primÃ¡ria de dados. As mudanÃ§as lÃ³gicas capturadas do banco de dados sÃ£o transformadas em eventos que fluem atravÃ©s do Kafka atÃ© os destinos finais.

### Arquitetura Implementada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL Fonte              â”‚
â”‚  (ReplicaÃ§Ã£o LÃ³gica - WAL)     â”‚ â† FONTE: MudanÃ§as LÃ³gicas do Banco
â”‚  wal_level=logical             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ MudanÃ§as LÃ³gicas (INSERT/UPDATE/DELETE)
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Debezium Source Connector    â”‚ â† Captura mudanÃ§as via WAL
â”‚   (Logical Replication Slot)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Eventos CDC (Avro)
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka + Schema Registry       â”‚ â† Streaming de Eventos
â”‚   (TÃ³picos Avro)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â–¼                  â–¼                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PostgreSQL   â”‚    â”‚    MinIO      â”‚    â”‚   (Futuro)   â”‚
    â”‚    Sink      â”‚    â”‚   (S3/Parquet)â”‚    â”‚   DuckDB     â”‚
    â”‚  (JDBC Sink) â”‚    â”‚  (S3 Sink)    â”‚    â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CaracterÃ­sticas Principais

1. **Fonte de Dados: MudanÃ§as LÃ³gicas do Banco**
   - Utiliza a replicaÃ§Ã£o lÃ³gica do PostgreSQL (`wal_level=logical`)
   - Captura mudanÃ§as atravÃ©s do WAL (Write-Ahead Log)
   - NÃ£o requer modificaÃ§Ãµes na aplicaÃ§Ã£o fonte
   - Captura eventos de INSERT, UPDATE e DELETE automaticamente

2. **Captura de MudanÃ§as (CDC)**
   - Debezium conecta-se ao PostgreSQL via slot de replicaÃ§Ã£o lÃ³gica
   - Cada mudanÃ§a no banco gera um evento no Kafka
   - Schemas Avro garantem compatibilidade e evoluÃ§Ã£o

3. **DistribuiÃ§Ã£o para MÃºltiplos Destinos**
   - **PostgreSQL Sink**: ReplicaÃ§Ã£o sÃ­ncrona via JDBC Sink Connector
   - **MinIO (S3)**: Armazenamento em formato Parquet para anÃ¡lise
   - Arquitetura extensÃ­vel para adicionar mais destinos

### Tecnologias Utilizadas

- **PostgreSQL**: Banco de dados com replicaÃ§Ã£o lÃ³gica habilitada
- **Debezium**: Conector source para CDC via replicaÃ§Ã£o lÃ³gica
- **Apache Kafka**: Broker de mensagens para streaming
- **Schema Registry**: Gerenciamento de schemas Avro
- **Kafka Connect**: Framework para integraÃ§Ã£o de sistemas
- **MinIO**: Armazenamento S3-compatible
- **Docker & Docker Compose**: ContainerizaÃ§Ã£o e orquestraÃ§Ã£o

### Estrutura do Trabalho

O trabalho estÃ¡ localizado na pasta `trabalho/` e contÃ©m:

```
trabalho/
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o de todos os serviÃ§os
â”œâ”€â”€ connectors/                 # ConfiguraÃ§Ãµes dos conectores
â”‚   â”œâ”€â”€ debezium-source.json    # Conector Debezium (captura mudanÃ§as lÃ³gicas)
â”‚   â”œâ”€â”€ jdbc-sink-postgres.json # Conector JDBC Sink (PostgreSQL)
â”‚   â””â”€â”€ s3-sink-minio.json      # Conector S3 Sink (MinIO/Parquet)
â”œâ”€â”€ scripts/                    # Scripts de execuÃ§Ã£o
â”‚   â”œâ”€â”€ setup.sh                # ConfiguraÃ§Ã£o inicial do pipeline
â”‚   â”œâ”€â”€ initial_load.py         # Carga inicial de dados
â”‚   â”œâ”€â”€ mutations.py            # Testes de INSERT/UPDATE/DELETE
â”‚   â”œâ”€â”€ validate.sh             # ValidaÃ§Ã£o dos dados nos destinos
â”‚   â””â”€â”€ reset.sh                # Reset do ambiente
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â””â”€â”€ README.md                   # DocumentaÃ§Ã£o completa do trabalho
```

### Como Executar

Para executar o trabalho, siga as instruÃ§Ãµes detalhadas no README do trabalho:

```bash
cd trabalho
# Siga as instruÃ§Ãµes em trabalho/README.md
```

**Passos rÃ¡pidos:**
1. `docker-compose up -d` - Subir todos os serviÃ§os
2. `bash scripts/setup.sh` - Configurar o pipeline
3. `python scripts/initial_load.py` - Carga inicial
4. `python scripts/mutations.py` - Testar mutaÃ§Ãµes
5. `bash scripts/validate.sh` - Validar resultados

### Diferenciais da ImplementaÃ§Ã£o

1. **Uso de ReplicaÃ§Ã£o LÃ³gica**: A fonte de dados sÃ£o as mudanÃ§as lÃ³gicas capturadas diretamente do WAL do PostgreSQL, nÃ£o polling ou triggers
2. **Zero Impacto na AplicaÃ§Ã£o**: NÃ£o requer modificaÃ§Ãµes no cÃ³digo da aplicaÃ§Ã£o fonte
3. **Tempo Real**: Captura de mudanÃ§as em tempo real atravÃ©s do slot de replicaÃ§Ã£o
4. **MÃºltiplos Destinos**: DemonstraÃ§Ã£o de distribuiÃ§Ã£o para pelo menos 2 destinos diferentes
5. **Reprodutibilidade**: Pipeline completamente containerizado e automatizado

### Requisitos Atendidos

âœ… Pipeline CDC reprodutÃ­vel (Docker Compose)  
âœ… Fonte de dados: MudanÃ§as lÃ³gicas do banco (WAL)  
âœ… Captura de INSERT, UPDATE e DELETE  
âœ… DistribuiÃ§Ã£o para â‰¥ 2 destinos (PostgreSQL e MinIO)  
âœ… Uso de Schema Registry com Avro  
âœ… Scripts automatizados de setup e validaÃ§Ã£o  
âœ… DocumentaÃ§Ã£o completa

### Integrantes

- **Rafael Lima Tavares** - MatrÃ­cula: [ADICIONAR MATRÃCULA]
- **Dante Dantes** - MatrÃ­cula: [ADICIONAR MATRÃCULA]

**InstituiÃ§Ã£o**: Universidade de Fortaleza (UNIFOR)  
**Disciplina**: Arquitetura de MicroserviÃ§os  
**Curso**: MBA Engenharia de Dados

---

## ğŸ“– Aulas PrÃ¡ticas

### Aula 01: IntroduÃ§Ã£o ao Kafka
DemonstraÃ§Ãµes bÃ¡sicas de produtores e consumidores Kafka.

### Aula 02: Schemas e SerializaÃ§Ã£o
Uso de Avro e Schema Registry para garantir contratos de dados.

### Aula 03: TÃ³picos, PartiÃ§Ãµes, ReplicaÃ§Ã£o e Connect
- PartiÃ§Ãµes e offsets
- ReplicaÃ§Ã£o e tolerÃ¢ncia a falhas
- Kafka Connect e conectores
- Consumer groups e lag

### Aula 04: Domain-Driven Design
AplicaÃ§Ã£o de conceitos de DDD em sistemas distribuÃ­dos.

### Aula 05: CQRS e TransaÃ§Ãµes
- Command Query Responsibility Segregation
- TransaÃ§Ãµes distribuÃ­das no Kafka
- Read models e projections

---

## ğŸ› ï¸ PrÃ©-requisitos

- Docker e Docker Compose
- Python 3.8+
- Git

## ğŸ“ LicenÃ§a

Este repositÃ³rio contÃ©m material didÃ¡tico da disciplina de Arquitetura de MicroserviÃ§os.

---

**Ãšltima atualizaÃ§Ã£o**: Dezembro 2024
